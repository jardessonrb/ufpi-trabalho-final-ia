# -*- coding: utf-8 -*-
"""classificacao_boots.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V-79-O_7NafurmLOb1MsnnxoeXakSzwb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import classification_report, confusion_matrix

sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/comentarios_estruturados_v2.csv'

df = pd.read_csv(file_path)

df.head()

features = [
    'comment_publishedAt',
    'seconds_after_video',
    'seconds_after_comment',
    'subscriber_count',
    'video_count',
    'view_count',
    'created_channel',
    'comment_lenght',
    'comment_is_number'
]

df['comment_publishedAt'] = pd.to_datetime(df['comment_publishedAt'], errors='coerce')
df['comment_publishedAt'] = df['comment_publishedAt'].astype(np.int64) // 10**9


df.dropna(subset=features + ['bot'], inplace=True)

# Equilibrar os dados: pegar todos os bots e amostrar não-bots
# bots = df[df['bot'] == 1]
# print(len(bots))
# nao_bots = df[df['bot'] == 0].sample(n=len(bots), random_state=42)
# print(len(nao_bots))

# Dataset balanceado
# df_balanced = pd.concat([bots, nao_bots]).sample(frac=1, random_state=42)  # shuffle
df_balanced = df

X = df_balanced[features]
y = df_balanced['bot']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Normalizar os dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

sgd = SGDClassifier(random_state=42, max_iter=1500, tol=1e-3)
sgd.fit(X_train_scaled, y_train)

y_pred = sgd.predict(X_test_scaled)

print("Relatório de Classificação -  proporção 80 - 20 com dados balanceados:\n")
print(classification_report(y_test, y_pred, target_names=["Não Bot", "Bot"]))

cm = confusion_matrix(y_test, y_pred)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Não Bot", "Bot"], yticklabels=["Não Bot", "Bot"])
plt.title("Matriz de Confusão - SGD")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()

"""### **Teste de classificação com dados não usados no treinamento**"""

# Caminho do novo arquivo (substitua pelo nome correto)
novo_csv_path = '/content/drive/MyDrive/Colab Notebooks/dataset/comentarios_estruturados_eb_g3u6Xc0c.csv'  # ou use upload

# Carregar dados
df_novo = pd.read_csv(novo_csv_path)

# Features usadas no modelo
# features = [
#     # 'comment_publishedAt',
#     # 'seconds_after_video',
#     'seconds_after_comment',
#     'subscriber_count',
#     'video_count',
#     'view_count',
#     'created_channel',
#     'comment_lenght',
#     # 'comment_is_number'
# ]

# Pré-processamento: converter data
df_novo['comment_publishedAt'] = pd.to_datetime(df_novo['comment_publishedAt'], errors='coerce')
df_novo['comment_publishedAt'] = df_novo['comment_publishedAt'].astype(np.int64) // 10**9

# Remover registros com valores nulos nas features
df_novo.dropna(subset=features, inplace=True)

# Normalizar com o mesmo scaler usado no treino
X_novo = scaler.transform(df_novo[features])

# Prever com o modelo treinado
pred_novo = sgd.predict(X_novo)

# len(pred_novo)

# Anexar resultado à tabela original
df_novo['predito_bot'] = pred_novo

# Filtrar e exibir os classificados como bots
bots_detectados = df_novo[df_novo['predito_bot'] == 1]
print(f"Bots detectados: {len(bots_detectados)}")
bots_detectados.head(10)  # Mostrar os 10 primeiros bots detectados

"""## **Video sem rotulo do Samuel - Day Trade**"""

# Caminho do novo arquivo (substitua pelo nome correto)
novo_csv_path = '/content/drive/MyDrive/Colab Notebooks/dataset/comentarios_estruturados_ZcMHnzuinUI.csv'  # ou use upload

# Carregar dados
df_novo = pd.read_csv(novo_csv_path)

# # Features usadas no modelo
# features = [
#     # 'comment_publishedAt',
#     # 'seconds_after_video',
#     'seconds_after_comment',
#     'subscriber_count',
#     'video_count',
#     'view_count',
#     'created_channel',
#     'comment_lenght',
#     # 'comment_is_number'
# ]

# Pré-processamento: converter data
df_novo['comment_publishedAt'] = pd.to_datetime(df_novo['comment_publishedAt'], errors='coerce')
df_novo['comment_publishedAt'] = df_novo['comment_publishedAt'].astype(np.int64) // 10**9

# Remover registros com valores nulos nas features
df_novo.dropna(subset=features, inplace=True)

# Normalizar com o mesmo scaler usado no treino
X_novo = scaler.transform(df_novo[features])

# Prever com o modelo treinado
pred_novo = sgd.predict(X_novo)

# len(pred_novo)

# Anexar resultado à tabela original
df_novo['predito_bot'] = pred_novo
print(len(df_novo))

# Filtrar e exibir os classificados como bots
bots_detectados = df_novo[df_novo['predito_bot'] == 1]
print(f"Bots detectados: {len(bots_detectados)}")
# bots_detectados.head(30)  # Mostrar os 10 primeiros bots detectados
bots_unicos = bots_detectados[['author', 'channel_id']].drop_duplicates().reset_index(drop=True)
bots_detectados.head(34)

"""## **Video que o Samuel mandou de cripto**"""

import networkx as nx
import matplotlib.pyplot as plt

# Filtrar bots detectados
bots_detectados = df_novo[df_novo['predito_bot'] == 1]

# Ignorar auto-relacionamentos
bots_edges = bots_detectados[bots_detectados['channel_id'] != bots_detectados['root_channel_id']]

# Criar grafo direcionado
G_bots_detectados = nx.DiGraph()

# Adicionar arestas
edges = list(zip(bots_edges['channel_id'], bots_edges['root_channel_id']))
G_bots_detectados.add_edges_from(edges)

# Verificar tamanho
print(f"Nós: {G_bots_detectados.number_of_nodes()} | Arestas: {G_bots_detectados.number_of_edges()}")

# Visualização
plt.figure(figsize=(12, 8))
pos = nx.spring_layout(G_bots_detectados, k=0.5)

nx.draw(
    G_bots_detectados, pos,
    with_labels=True,
    node_color='orange',
    edge_color='gray',
    node_size=300,
    alpha=0.9,
    arrows=True
)

plt.title("Grafo de relacionamentos dos bots detectados")
plt.show()

# --- VISUALIZAÇÃO DO GRAFO DE BOTS USANDO APENAS DADOS DE TREINAMENTO COM BOTS CENTRAIS+SECUNDÁRIOS DESTACADOS ---

import networkx as nx
import matplotlib.pyplot as plt
from matplotlib.patches import Patch

# Construir grafo apenas com os dados de treinamento balanceados
df_bots_treino = df_balanced[df_balanced['bot'] == 1]
df_bots_treino_edges = df_bots_treino[
    df_bots_treino['channel_id'] != df_bots_treino['root_channel_id']
]

# Criar grafo direcionado
G_treino = nx.DiGraph()
G_treino.add_edges_from(zip(df_bots_treino_edges['channel_id'], df_bots_treino_edges['root_channel_id']))

# Identificar bots que aparecem como root_channel_id (centrais)
central_bots = set(df_bots_treino_edges['root_channel_id'])

# Identificar bots que aparecem como channel_id (secundários)
secondary_bots = set(df_bots_treino_edges['channel_id'])

# Bots que são centrais e secundários ao mesmo tempo
central_and_secondary_bots = central_bots.intersection(secondary_bots)
print(f"Bots que são centrais e secundários ao mesmo tempo: {len(central_and_secondary_bots)} encontrados.")

# Preparar cores:
# - Marrom: bots central e secundário
# - Verde: bots centrais
# - Azul: bots secundários
node_colors = []
for node in G_treino.nodes():
    if node in central_and_secondary_bots:
        node_colors.append('brown')
    elif node in central_bots:
        node_colors.append('green')
    elif node in secondary_bots:
        node_colors.append('skyblue')
    else:
        node_colors.append('gray')  # apenas por segurança, não deve ocorrer

# Visualização com layout espaçado
plt.figure(figsize=(14, 10))
pos = nx.spring_layout(G_treino, k=1.2, seed=42)

nx.draw(
    G_treino, pos,
    node_color=node_colors,
    edge_color='lightgray',
    with_labels=False,
    node_size=80,
    alpha=0.85,
    arrows=True
)

# Legenda
legend_elements = [
    Patch(facecolor='skyblue', label='Bot Secundário (Comenta)'),
    Patch(facecolor='green', label='Bot Central (Recebe Comentários)'),
    Patch(facecolor='brown', label='Bot Central + Secundário')
]
plt.legend(handles=legend_elements, loc='upper right')

plt.title('Grafo de Bots (Treinamento): Bots Centrais, Secundários e Ambos Destacados')
plt.show()

# Exibir os primeiros bots central+secundário identificados
print("Exemplo de Bots Centrais e Secundários ao mesmo tempo (primeiros 10 IDs):")
for i, bot_id in enumerate(list(central_and_secondary_bots)[:10], 1):
    print(f"{i}. {bot_id}")

# --- Construção e visualização do grafo completo dos dados de treinamento ---

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from matplotlib.patches import Patch

# Carregar dados de treinamento completos
file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/comentarios_estruturados_v2.csv'
df_treino_full = pd.read_csv(file_path)

# Filtrar apenas bots
df_bots_treino_full = df_treino_full[df_treino_full['bot'] == 1]

# Ignorar auto-relacionamentos
df_bots_treino_full_edges = df_bots_treino_full[df_bots_treino_full['channel_id'] != df_bots_treino_full['root_channel_id']]

# Construir grafo direcionado
G_full = nx.DiGraph()
edges = list(zip(df_bots_treino_full_edges['channel_id'], df_bots_treino_full_edges['root_channel_id']))
G_full.add_edges_from(edges)

# Identificar bots que comentaram em mais de um vídeo
# Um vídeo é identificado pelo root_channel_id; queremos bots que comentaram em mais de um root_channel_id
bot_video_counts = df_bots_treino_full.groupby('channel_id')['root_channel_id'].nunique()
bots_multi_video = set(bot_video_counts[bot_video_counts > 1].index)

print(f"Bots que comentaram em mais de um vídeo: {len(bots_multi_video)} encontrados.")

# Preparar cores para visualização
node_colors = []
for node in G_full.nodes():
    if node in bots_multi_video:
        node_colors.append('red')  # bots multi-vídeo
    else:
        node_colors.append('skyblue')  # bots normais

# Visualização
plt.figure(figsize=(16, 12))
pos = nx.spring_layout(G_full, k=0.6, seed=42)

nx.draw(
    G_full, pos,
    node_color=node_colors,
    edge_color='gray',
    with_labels=True,
    node_size=120,
    alpha=0.85,
    arrows=True
)

# Legenda
legend_elements = [
    Patch(facecolor='skyblue', label='Bots (1 vídeo)'),
    Patch(facecolor='red', label='Bots Multi-Vídeo')
]
plt.legend(handles=legend_elements, loc='upper right')

plt.title('Grafo dos Bots nos Dados de Treinamento (com Bots Multi-Vídeo Destacados)')
plt.show()

# Mostrar IDs dos bots multi-vídeo caso deseje inspecionar
print("Exemplo de Bots Multi-Vídeo (primeiros 10 IDs):")
for i, bot_id in enumerate(list(bots_multi_video)[:10], 1):
    print(f"{i}. {bot_id}")

# --- Grafo de bots de treinamento com root_channel_id destacados e espaçamento aumentado ---

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from matplotlib.patches import Patch

# Carregar os dados de treinamento completos
file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/comentarios_estruturados_v2.csv'
df_treino_full = pd.read_csv(file_path)

# Filtrar apenas bots
df_bots_treino_full = df_treino_full[df_treino_full['bot'] == 1]

# Ignorar auto-relacionamentos
df_bots_treino_full_edges = df_bots_treino_full[
    df_bots_treino_full['channel_id'] != df_bots_treino_full['root_channel_id']
]

# Criar o grafo direcionado
G_full = nx.DiGraph()
edges = list(zip(df_bots_treino_full_edges['channel_id'], df_bots_treino_full_edges['root_channel_id']))
G_full.add_edges_from(edges)

# Identificar bots multi-vídeo
bot_video_counts = df_bots_treino_full.groupby('channel_id')['root_channel_id'].nunique()
bots_multi_video = set(bot_video_counts[bot_video_counts > 1].index)

print(f"Bots multi-vídeo encontrados: {len(bots_multi_video)}")

# Identificar root_channel_id únicos
root_channels = set(df_bots_treino_full_edges['root_channel_id'])

# Preparar cores:
# - Vermelho: bots multi-vídeo
# - Verde: root_channel_id
# - Azul: bots normais
node_colors = []
for node in G_full.nodes():
    if node in bots_multi_video:
        node_colors.append('red')
    elif node in root_channels:
        node_colors.append('green')
    else:
        node_colors.append('skyblue')

# Visualização com espaçamento maior
plt.figure(figsize=(16, 12))
pos = nx.spring_layout(G_full, k=1.5, seed=42)  # k aumentado para espaçamento

nx.draw(
    G_full, pos,
    node_color=node_colors,
    edge_color='gray',
    with_labels=False,
    node_size=50,
    alpha=0.85,
    arrows=True
)

# Legenda
legend_elements = [
    Patch(facecolor='skyblue', label='Bots Em Pelo Menos 1 Vídeo'),
    Patch(facecolor='red', label='Bots Em Vários Vídeos'),
    Patch(facecolor='green', label='Bots Centrais')
]
plt.legend(handles=legend_elements, loc='upper right')

plt.title('Grafo de Bots (Treinamento) - Destaque Multi-Vídeo e Root_channel_id')
plt.show()

# Mostrar exemplo de bots multi-vídeo
print("Exemplos de Bots Multi-Vídeo (primeiros 10 IDs):")
for i, bot_id in enumerate(list(bots_multi_video)[:10], 1):
    print(f"{i}. {bot_id}")

# --- Análise dos Componentes Fortemente Conectados (SCC) ---

# Encontrar SCCs
sccs = list(nx.strongly_connected_components(G_treino))

# Ordenar por tamanho decrescente
sccs_sorted = sorted(sccs, key=len, reverse=True)

# Informações resumidas
print(f"Total de SCCs encontrados: {len(sccs_sorted)}")
print(f"Tamanho do maior SCC: {len(sccs_sorted[0])}")

# Mostrar os nós do maior SCC
print("\nNós do maior SCC (primeiros 10):")
for i, node in enumerate(list(sccs_sorted[0])[:10], 1):
    print(f"{i}. {node}")

# Visualizar o maior SCC
subG_scc = G_treino.subgraph(sccs_sorted[0])
plt.figure(figsize=(8, 6))
pos = nx.spring_layout(subG_scc, k=0.8, seed=42)
nx.draw(
    subG_scc, pos,
    with_labels=False,
    node_color='lightgreen',
    edge_color='gray',
    node_size=30,
    alpha=0.9
)
plt.title('Maior Componente Fortemente Conectado (SCC)')
plt.show()

# --- Densidade e Diâmetro da Rede ---

# Densidade
densidade = nx.density(G_treino)
print(f"Densidade da rede: {densidade:.6f}")

# Diâmetro (apenas para grafos fortemente conectados)
if nx.is_strongly_connected(G_treino):
    diametro = nx.diameter(G_treino)
    print(f"Diâmetro da rede: {diametro}")
else:
    # Para grafos não fortemente conectados, calcular no maior SCC
    largest_scc = max(nx.strongly_connected_components(G_treino), key=len)
    subG_scc = G_treino.subgraph(largest_scc)
    diametro_scc = nx.diameter(subG_scc)
    print(f"A rede não é fortemente conectada.")
    print(f"Diâmetro do maior SCC: {diametro_scc}")

# --- Assortatividade de Grau ---

# Calcular assortatividade de grau (direcionado)
# Usa a correlação entre o grau de saída de um nó e o grau de entrada dos seus vizinhos
assortatividade = nx.degree_pearson_correlation_coefficient(G_treino)

print(f"Assortatividade de grau da rede: {assortatividade:.4f}")

# Interpretação inicial:
if assortatividade > 0:
    print("Interpretação: A rede tende a conectar nós de graus semelhantes (positiva).")
elif assortatividade < 0:
    print("Interpretação: A rede tende a conectar nós de graus diferentes (negativa).")
else:
    print("Interpretação: Sem correlação de grau aparente.")

# --- Análise de Componentes Fracamente Conectados (WCC) no grafo de bots de treinamento ---

import matplotlib.pyplot as plt
import networkx as nx

# Encontrar componentes fracamente conectados
wccs = list(nx.weakly_connected_components(G_treino))

# Ordenar por tamanho decrescente
wccs_sorted = sorted(wccs, key=len, reverse=True)

print(f"Total de componentes fracamente conectados (WCC) encontrados: {len(wccs_sorted)}")
print(f"Tamanho do maior WCC: {len(wccs_sorted[0])}")

# Mostrar os primeiros nós do maior WCC
print("\nNós do maior WCC (primeiros 10 IDs):")
for i, node in enumerate(list(wccs_sorted[0])[:10], 1):
    print(f"{i}. {node}")

# Visualizar o maior WCC
subG_wcc = G_treino.subgraph(wccs_sorted[0])

plt.figure(figsize=(10, 8))
pos = nx.spring_layout(subG_wcc, k=0.9, seed=42)
nx.draw(
    subG_wcc, pos,
    with_labels=False,
    node_color='skyblue',
    edge_color='gray',
    node_size=80,
    alpha=0.9,
    arrows=False
)

plt.title('Maior Componente Fracamente Conectado (WCC) - Rede de Bots')
plt.show()

# Estatísticas complementares
tamanhos = [len(c) for c in wccs_sorted]
print(f"Tamanho médio dos WCCs: {sum(tamanhos)/len(tamanhos):.2f}")
print(f"Top 5 tamanhos de WCCs: {tamanhos[:5]}")

"""## **Mostrandos quais features foram mais releventes no processo de classificação**
- Foram removidos alguns features ( 'comment_publishedAt', 'seconds_after_video', 'comment_lenght', 'comment_is_number') Por que em alguns cenários vimos que tinhamos bots com comportamentos diferentes, alguns possuim vídeos e comentavam depois de alguns dias do lançamento do vídeo)

"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Verificar se o modelo tem coef_ (ele deve ter após o treino)
if hasattr(sgd, 'coef_'):
    # Coeficientes do modelo linear
    coef = sgd.coef_[0]

    # Features usadas
    feature_names = [
        'comment_publishedAt',
        'seconds_after_video',
        'seconds_after_comment',
        'subscriber_count',
        'video_count',
        'view_count',
        'created_channel',
        'comment_lenght',
        'comment_is_number'
    ]

    # Montar DataFrame com importâncias
    df_importancia = pd.DataFrame({
        'Feature': feature_names,
        'Importância': np.abs(coef)
    }).sort_values(by='Importância', ascending=False)

    # Visualização
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_importancia, x='Importância', y='Feature', palette='Blues_d')
    plt.title('Importância das Features no Modelo SGD')
    plt.xlabel('Valor Absoluto do Coeficiente')
    plt.ylabel('Feature')
    plt.tight_layout()
    plt.show()

    # Mostrar a tabela
    display(df_importancia)
else:
    print("Modelo SGD ainda não foi treinado ou não possui coef_")

import networkx as nx
import matplotlib.pyplot as plt

# Filtrar bots detectados
bots_detectados = df_novo[df_novo['predito_bot'] == 1]

# Ignorar auto-relacionamentos
bots_edges = bots_detectados[bots_detectados['channel_id'] != bots_detectados['root_channel_id']]

# Criar grafo direcionado
G_bots_detectados = nx.DiGraph()

# Adicionar arestas
edges = list(zip(bots_edges['channel_id'], bots_edges['root_channel_id']))
G_bots_detectados.add_edges_from(edges)

# Verificar tamanho
print(f"Nós: {G_bots_detectados.number_of_nodes()} | Arestas: {G_bots_detectados.number_of_edges()}")

# Visualização
plt.figure(figsize=(12, 8))
pos = nx.spring_layout(G_bots_detectados, k=0.5)

nx.draw(
    G_bots_detectados, pos,
    with_labels=True,
    node_color='orange',
    edge_color='gray',
    node_size=300,
    alpha=0.9,
    arrows=True
)

plt.title(f'Grafo de relacionamentos dos bots detectados{"" if G_bots_detectados.number_of_nodes() != 0 else " [Nenhum nó encontrado]"}')
plt.show()

from matplotlib.patches import Patch

# Criar uma cópia para não alterar os originais
G_treino = G.copy()  # G: grafo dos bots rotulados (do treino)
G_teste = G_bots_detectados.copy()  # G_bots_detectados: do teste

# Unir os dois grafos
G_unido = nx.compose(G_treino, G_teste)

# Marcar os tipos de bots nos nós
tipo_no = {}
for node in G_unido.nodes():
    if node in G_treino and node in G_teste:
        tipo_no[node] = 'ambos'
    elif node in G_treino:
        tipo_no[node] = 'treino'
    elif node in G_teste:
        tipo_no[node] = 'teste'

# Definir cores
cores = {
    'treino': 'steelblue',
    'teste': 'orange',
    'ambos': 'purple'
}
node_colors = [cores[tipo_no[n]] for n in G_unido.nodes()]

# Visualizar grafo unificado
plt.figure(figsize=(14, 10))
pos = nx.spring_layout(G_unido, k=0.6)

nx.draw(
    G_unido, pos,
    with_labels=True,
    node_color=node_colors,
    edge_color='gray',
    node_size=400,
    alpha=0.85,
    arrows=True
)

# Adicionar legenda
legend_elements = [
    Patch(facecolor='steelblue', label='Rotulado '),
    Patch(facecolor='orange', label='Detectado (teste)'),
    Patch(facecolor='purple', label='Presente nos dois')
]
plt.legend(handles=legend_elements, loc='upper right')

plt.title("Grafo unificado: bots rotulados (treino) + bots detectados (teste)")
plt.show()

"""Novos bost encontrados - Samuel Day Trader"""

# 1. Criar grafo dos novos bots detectados
edges_novos = bots_detectados[bots_detectados['channel_id'] != bots_detectados['root_channel_id']]
G_detectados2 = nx.DiGraph()
G_detectados2.add_edges_from(zip(edges_novos['channel_id'], edges_novos['root_channel_id']))

# 2. Unir com o grafo anterior (G_unido já existe: treino + teste 1)
G_expandido = nx.compose(G_unido, G_detectados2)

# 3. Marcar tipos dos nós
tipo_no_expandido = {}
for node in G_expandido.nodes():
    em_treino = node in G_treino
    em_teste1 = node in G_teste
    em_teste2 = node in G_detectados2

    if em_treino and em_teste2:
        tipo_no_expandido[node] = 'treino + detectado_2'
    elif em_teste1 and em_teste2:
        tipo_no_expandido[node] = 'ambos_detectados'
    elif em_treino:
        tipo_no_expandido[node] = 'treino'
    elif em_teste1:
        tipo_no_expandido[node] = 'detectado_1'
    elif em_teste2:
        tipo_no_expandido[node] = 'detectado_2'
    else:
        tipo_no_expandido[node] = 'outro'

# 4. Cores
cores_expandido = {
    'treino': 'steelblue',
    'detectado_1': 'orange',
    'detectado_2': 'green',
    'ambos_detectados': 'purple',
    'treino + detectado_2': 'brown',
    'outro': 'gray'
}
node_colors = [cores_expandido[tipo_no_expandido[n]] for n in G_expandido.nodes()]

# 5. Visualização
plt.figure(figsize=(15, 11))
pos = nx.spring_layout(G_expandido, k=0.6)

nx.draw(
    G_expandido, pos,
    with_labels=False,
    node_color=node_colors,
    edge_color='lightgray',
    node_size=350,
    alpha=0.9,
    arrows=True
)

# Legenda
from matplotlib.patches import Patch
legend_elements = [
    Patch(color='steelblue', label='Rotulado (treino)'),
    Patch(color='orange', label='Detectado 1° conjunto'),
    Patch(color='green', label='Detectado 2° conjunto'),
    Patch(color='purple', label='Detectado em ambos'),
    Patch(color='brown', label='Treino + Detectado 2'),
    Patch(color='gray', label='Outro')
]
plt.legend(handles=legend_elements, loc='best')
plt.title("Grafo expandido: Rotulados + Detectados (2 conjuntos)")
plt.show()

# Instalar a biblioteca correta (python-louvain)
!pip install -q python-louvain

import matplotlib.pyplot as plt
import networkx as nx
import matplotlib.colors as mcolors

# Importar o módulo correto com alias
import community.community_louvain as community_louvain

# 1. Converter grafo para não-direcionado
G_undirected = G_expandido.to_undirected()

# 2. Aplicar algoritmo de Louvain
partition = community_louvain.best_partition(G_undirected)

# 3. Gerar cores para comunidades
cores_disponiveis = list(mcolors.TABLEAU_COLORS.values()) + list(mcolors.CSS4_COLORS.values())
node_colors = [cores_disponiveis[partition[n] % len(cores_disponiveis)] for n in G_undirected.nodes()]

# 4. Visualizar o grafo com cores por cluster
plt.figure(figsize=(15, 11))
pos = nx.spring_layout(G_undirected, k=0.6)

nx.draw(
    G_undirected, pos,
    node_color=node_colors,
    with_labels=False,
    edge_color='lightgray',
    node_size=350,
    alpha=0.9
)

plt.title(f"Clusters no grafo expandido (Louvain) - {len(set(partition.values()))} comunidades detectadas")
plt.show()

# Nós dos dois grafos
nodos_treino = set(G.nodes())
nodos_teste = set(G_bots_detectados.nodes())

# Interseção (bots em ambos)
bots_em_ambos = nodos_treino.intersection(nodos_teste)

print(f"Total de bots presentes em ambos: {len(bots_em_ambos)}\n")
print("Channel IDs dos bots detectados e já rotulados:")

for i, node in enumerate(bots_em_ambos):
    print(f"{i+1}. {node}")

from sklearn.linear_model import SGDClassifier

if hasattr(sgd, 'decision_function'):
    confidencias = sgd.decision_function(X_novo)
    df_novo['score'] = confidencias
    df_novo.sort_values(by='score').head(10)  # menores = mais "bot"

"""## **Criação dos grafos da rede**"""

import networkx as nx

# Substitua pelo caminho correto ou carregue direto no Colab
file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/comentarios_estruturados.csv'  # ou use o botão de upload

df_grafo = pd.read_csv(file_path)

# Exibe os dados principais
df_grafo.head()

# Filtrar apenas os comentários marcados como bots
df_bots = df_grafo[df_grafo['bot'] == 1]

# Ignorar auto-referência (comentou em si mesmo)
df_bots_edges = df_bots[df_bots['channel_id'] != df_bots['root_channel_id']]

# Criar grafo direcionado
G = nx.DiGraph()

# Adicionar arestas de relacionamento entre bots
edges = list(zip(df_bots_edges['channel_id'], df_bots_edges['root_channel_id']))
G.add_edges_from(edges)

print(f"Número de nós: {G.number_of_nodes()}")
print(f"Número de arestas: {G.number_of_edges()}")

# Ajustar tamanho baseado no número de nós
num_nodes = G.number_of_nodes()
node_size = 100 if num_nodes < 200 else 20

plt.figure(figsize=(12, 8))
pos = nx.spring_layout(G, k=0.5, iterations=50)  # layout com melhor separação

# Desenhar grafo
nx.draw(
    G, pos,
    with_labels=False,
    node_color='skyblue',
    edge_color='gray',
    node_size=node_size,
    alpha=0.8,
    arrows=True
)

plt.title("Grafo de relacionamento entre bots (canal → canal raiz)")
plt.show()

"""Resposta ao conjunto ser conectado
 Interpretação:
- Os bots estão concentrados em grandes grupos conectados (coordenação possível).
- Não há bots agindo isoladamente (ou com poucos vínculos), o que pode indicar
campanha organizada, resposta em massa ou botnet unificada.

## **Visulizar componentes fracos**
"""

# Encontrar componentes fracos no grafo
componentes = list(nx.weakly_connected_components(G))

# Ordenar por tamanho crescente
componentes_ordenados = sorted(componentes, key=len)

# Filtrar componentes pequenos (ex: com até 3 nós)
componentes_pequenos = [c for c in componentes_ordenados if len(c) <= 3]

print(f"Total de componentes encontrados: {len(componentes)}")
print(f"Componentes pequenos (≤ 3 nós): {len(componentes_pequenos)}")

# Mostrar os primeiros componentes pequenos
for i, comp in enumerate(componentes_pequenos[:5]):
    print(f"\nGrupo {i+1} ({len(comp)} bots):")
    for node in comp:
        print(f"- {node}")

# Tamanhos dos componentes
tamanhos = [len(c) for c in componentes]

for i, tamanho in enumerate(tamanhos):
    print(f"Componente {i+1}: {tamanho} nós")

# Selecionar o menor componente
menor_componente = componentes_ordenados[0]
subG_menor = G.subgraph(menor_componente)

plt.figure(figsize=(8, 6))
pos = nx.spring_layout(subG_menor, k=0.5)
nx.draw(
    subG_menor, pos,
    with_labels=True,
    node_color='lightgreen',
    edge_color='gray',
    node_size=400,
    alpha=0.9,
    arrows=True
)
plt.title("Visualização do menor grupo conectado de bots")
plt.show()

# Nós com maior número de respostas (grau de saída)
graus_saida = G.out_degree()
top_saida = sorted(graus_saida, key=lambda x: x[1], reverse=True)[:10]

print("Top 10 bots com mais respostas:")
for node, grau in top_saida:
    print(f"- {node}: {grau} respostas")

# Calcular grau de entrada (quantas vezes um canal foi respondido)
graus_entrada = G.in_degree()

# Ordenar do maior para o menor
top_respondidos = sorted(graus_entrada, key=lambda x: x[1], reverse=True)

# Mostrar os 10 bots com mais respostas
print("Top 10 bots mais respondidos (por channel_id):")
for i, (channel_id, grau) in enumerate(top_respondidos[:10]):
    print(f"{i+1}. {channel_id} - {grau} respostas")